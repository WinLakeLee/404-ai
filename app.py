"""
404-AI orchestrator (Flask): proxies image uploads to vision  services.
Inference service: app.py (YOLO + PatchCore)
"""

import os
import json
import requests
import sys
from concurrent.futures import ThreadPoolExecutor
import uuid
from flask import Flask, jsonify, request
from mqtt_utils import (
    publish_with_client,
    publish_mqtt,
    is_client_connected,
    start_paho_listener,
)
import threading
from datetime import datetime
import time
from dotenv import load_dotenv
from pipeline import Pipeline
import tempfile
import numpy as np
from PIL import Image
import io
import copy
import re
import base64
from _daily_logger import DailyLogger
from itertools import count

# Load environment variables from .env (or DOTENV_PATH) before reading any settings
load_dotenv(dotenv_path=os.environ.get("DOTENV_PATH", ".env"), override=True)

app = Flask(__name__)
_EXECUTOR = ThreadPoolExecutor(max_workers=int(os.environ.get("APP_WORKERS", 4)))
dlogger = DailyLogger()

# Create a per-process upload session directory at app start to avoid
# filename collisions when multiple images arrive with the same timestamps.
# Files will be saved under debug/session_<YYYYMMDD>T<HHMMSS>/ and named 1.ext, 2.ext, ...
_UPLOAD_SESSION = datetime.now().strftime("session_%Y%m%dT%H%M%S")
_UPLOAD_DIR = os.path.join(os.getcwd(), "debug", _UPLOAD_SESSION)
os.makedirs(_UPLOAD_DIR, exist_ok=True)
# thread-safe counter for filenames
_UPLOAD_COUNTER = count(1)
_UPLOAD_COUNTER_LOCK = threading.Lock()

# MQTT settings (single broker for pub/sub)
_MQTT_BROKER = os.environ.get("MQTT_BROKER") or "localhost"

_MQTT_PORT = int(os.environ.get("MQTT_PORT") or 1883)
_MQTT_TLS = (os.environ.get("MQTT_TLS") or "0").lower() in ("1", "true", "yes")
_MQTT_KEEPALIVE = int(os.environ.get("MQTT_KEEPALIVE", 60))
_IN_TOPIC = os.environ.get("IN_MQTT_TOPIC") or "camera01/control"
_OUT_TOPIC = os.environ.get("MQTT_TOPIC") or "camera01/result"
_OUT_QOS = int(os.environ.get("OUT_MQTT_QOS") or os.environ.get("MQTT_QOS") or 1)

# ACK behavior: don't publish ACKs to the main result topic by default.
# Set `MQTT_SEND_ACK=1` to enable ACKs, and `MQTT_ACK_TOPIC` to change the ack topic.
_MQTT_SEND_ACK = (os.environ.get("MQTT_SEND_ACK") or "0").lower() in ("1", "true", "yes")
_MQTT_ACK_TOPIC = os.environ.get("MQTT_ACK_TOPIC") or None

# Whether to force `data:image/jpeg;base64,` prefix on published result_image
_FORCE_DATA_URI_PREFIX = (os.environ.get("FORCE_DATA_URI_HEADER") or "1").lower() in ("1", "true", "yes")

app.config["MQTT_BROKER_URL"] = _MQTT_BROKER
app.config["MQTT_BROKER_PORT"] = _MQTT_PORT
app.config["MQTT_KEEPALIVE"] = _MQTT_KEEPALIVE
app.config["MQTT_TLS_ENABLED"] = _MQTT_TLS
app.config["MQTT_CLEAN_SESSION"] = True

# MQTT client will be started after `process_image` is defined to avoid
# forward-reference issues with static analyzers (e.g., Pylance).
_MQTT_CLIENT = None


# Start a background monitor that periodically prints MQTT connection info.
def _start_mqtt_monitor(interval: int = 10):
    def _monitor():
        prev_connected = None
        while True:
            try:
                connected = is_client_connected(_MQTT_CLIENT)
                now = datetime.now().isoformat()
                # Log only on state change (or first check)
                if prev_connected is None:
                    dlogger.log(
                        f"[{now}] MQTT status: connected={connected} broker={_MQTT_BROKER}:{_MQTT_PORT} in_topic={_IN_TOPIC} out_topic={_OUT_TOPIC}",
                        level="info",
                    )
                elif connected != prev_connected:
                    dlogger.log(
                        f"[{now}] MQTT status changed: connected={connected} broker={_MQTT_BROKER}:{_MQTT_PORT}",
                        level="info",
                    )
                prev_connected = connected
            except Exception:
                dlogger.log(f"[{datetime.now().isoformat()}] MQTT status: check failed", level="warning")
            time.sleep(interval)

    t = threading.Thread(target=_monitor, daemon=True)
    t.start()


_start_mqtt_monitor()


# Image format validation functions
def validate_image_format(data: bytes) -> dict:
    """
    ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°ì˜ í˜•ì‹ì„ ê²€ì¦í•˜ê³  íŒŒì¼ í™•ì¥ì, MIME íƒ€ì… ë°˜í™˜

    Returns:
        {
            'valid': bool,
            'format': str (jpg, png, bmp, etc),
            'extension': str (.jpg, .png, etc),
            'mime_type': str,
            'size': int (bytes),
            'width': int,
            'height': int,
            'error': str (if valid=False)
        }
    """
    if not data or len(data) == 0:
        return {"valid": False, "error": "ì´ë¯¸ì§€ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    # íŒŒì¼ ì‹œê·¸ë‹ˆì²˜(ë§¤ì§ ë„˜ë²„)ë¡œ í˜•ì‹ ê²€ì¦
    magic_numbers = {
        b"\xff\xd8\xff": ("jpg", ".jpg", "image/jpeg"),  # JPEG
        b"\x89PNG": ("png", ".png", "image/png"),  # PNG
        b"BM": ("bmp", ".bmp", "image/bmp"),  # BMP
        b"GIF87a": ("gif", ".gif", "image/gif"),  # GIF87a
        b"GIF89a": ("gif", ".gif", "image/gif"),  # GIF89a
    }

    detected_format = None
    for magic, (fmt, ext, mime) in magic_numbers.items():
        if data.startswith(magic):
            detected_format = (fmt, ext, mime)
            break

    if not detected_format:
        return {
            "valid": False,
            "size": len(data),
            "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤ (ì²˜ìŒ 4ë°”ì´íŠ¸: {data[:4].hex()})",
        }

    fmt, ext, mime = detected_format

    # ì´ë¯¸ì§€ ì•ˆì „ì„± ê²€ì‚¬: PIL ê²€ì¦, ì¹˜ìˆ˜/í”½ì…€ìˆ˜ ì œí•œ, ì˜ì‹¬ ì„œëª… ìŠ¤ìº”
    try:
        # í™˜ê²½ ë³€ìˆ˜ë¡œ ì œí•œê°’ì„ ì¡°ì • ê°€ëŠ¥
        try:
            max_pixels = int(os.environ.get("IMAGE_MAX_PIXELS", "30000000"))
        except Exception:
            max_pixels = 30000000
        Image.MAX_IMAGE_PIXELS = max_pixels

        # ë¨¼ì € ë¹ ë¥´ê²Œ ê²€ì¦(verify)í•˜ì—¬ ì†ìƒ ì—¬ë¶€ í™•ì¸
        img = Image.open(io.BytesIO(data))
        img.verify()

        # ì‹¤ì œ í¬ê¸°ë¥¼ ì–»ê¸° ìœ„í•´ ë‹¤ì‹œ ì—´ê¸°
        img = Image.open(io.BytesIO(data))
        width, height = img.size

        try:
            max_w = int(os.environ.get("IMAGE_MAX_WIDTH", "10000"))
            max_h = int(os.environ.get("IMAGE_MAX_HEIGHT", "10000"))
            min_w = int(os.environ.get("IMAGE_MIN_WIDTH", "1"))
            min_h = int(os.environ.get("IMAGE_MIN_HEIGHT", "1"))
        except Exception:
            max_w, max_h, min_w, min_h = 10000, 10000, 1, 1

        if width <= 0 or height <= 0:
            return {"valid": False, "size": len(data), "error": "ì´ë¯¸ì§€ ì¹˜ìˆ˜ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}

        if width < min_w or height < min_h:
            return {"valid": False, "size": len(data), "error": f"ì´ë¯¸ì§€ ì¹˜ìˆ˜ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ ({width}x{height})"}

        if width > max_w or height > max_h:
            return {"valid": False, "size": len(data), "error": f"ì´ë¯¸ì§€ ì¹˜ìˆ˜ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤ ({width}x{height})"}

        # ê°„ë‹¨í•œ ì„œëª… ìŠ¤ìº”: í—¤ë”/ì•ë¶€ë¶„ì—ì„œ ìŠ¤í¬ë¦½íŠ¸/ì‹¤í–‰ íŒŒì¼/ì••ì¶• ì•„ì¹´ì´ë¸Œ í”ì  ê²€ì¶œ
        head = data[:4096].lower()
        suspicious_signatures = [b"<?php", b"<script", b"javascript:", b"pk\x03\x04", b"mz", b"#!/bin/sh", b"<!doctype html"]
        for sig in suspicious_signatures:
            if sig in head:
                return {"valid": False, "size": len(data), "error": f"ì˜ì‹¬ ì„œëª… ë°œê²¬: {sig.decode('latin1', 'ignore')}"}

        return {
            "valid": True,
            "format": fmt,
            "extension": ext,
            "mime_type": mime,
            "size": len(data),
            "width": width,
            "height": height,
        }
    except Image.DecompressionBombError as e:
        return {"valid": False, "size": len(data), "error": f"ì´ë¯¸ì§€ ë””ì»´í”„ë ˆìŠ¤ í­íƒ„ ì˜ì‹¬: {str(e)}"}
    except Exception as e:
        return {"valid": False, "size": len(data), "format": fmt, "error": f"ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {str(e)}"}


def aggregate_batch_response(responses: list, include_images: bool = False) -> dict:
    """
    Given a list of per-image response dicts (as returned by `process_image`),
    compute the aggregated top-level response structure used by HTTP `/detect`
    and MQTT publications.

    Returns a dict with keys: result, scratch_count, broken_count,
    separated_count, result_image (list), car_regions (list), reason, timestamp
    """
    total_scratch_count = 0
    total_broken_count = 0
    total_separated_count = 0
    total_car_regions = []
    result_images = []
    detected_any = False
    reasons = []

    for resp in responses:
        det = resp.get("detection", {})
        total_scratch_count += det.get("scratch_count", 0)
        total_broken_count += det.get("broken_count", 0)
        total_separated_count += det.get("separated_count", 0)
        total_car_regions.extend(det.get("car_regions", []))
        rimg = det.get("result_image")
        if rimg:
            if not isinstance(rimg, str):
                rimg = str(rimg)
            if not rimg.startswith("data:image/jpeg;base64,"):
                rimg = f"data:image/jpeg;base64,{rimg.lstrip()}"
            result_images.append(rimg)
        else:
            result_images.append("")
        if det.get("result") != "pass":
            detected_any = True
        if "reason" in det:
            reasons.append(det.get("reason"))

    aggregated = {
        "result": "defect" if detected_any else "ok",
        "detection": {
            "scratch_count": total_scratch_count,
            "broken_count": total_broken_count,
            "separated_count": total_separated_count,
            "result_image": result_images,
            "car_regions": total_car_regions,
            "reason": "; ".join(reasons) if reasons else None,
        },
        "timestamp": datetime.now().isoformat(),
    }
    # Optionally include per-image detailed responses normalized for publish
    if include_images:
        sanitized = []
        # whitelist of top-level keys to keep per-image
        keep_top = ("id", "result", "timestamp")
        # whitelist of detection fields considered safe
        keep_det = {
            "result",
            "scratch_count",
            "broken_count",
            "separated_count",
            "result_image",
            "car_regions",
            "reason",
            "success",
            "scratch_detected",
            "broken_detected",
            "separated_detected",
            "anomaly_detected",
        }

        for r in responses:
            new_r = {}
            for k in keep_top:
                if k in r:
                    new_r[k] = r[k]

            det = r.get("detection", {}) or {}
            new_det = {}
            for k in keep_det:
                if k in det:
                    v = det.get(k)
                    if k == "result_image":
                        if v:
                                if not isinstance(v, str):
                                    v = str(v)
                                if _FORCE_DATA_URI_PREFIX:
                                    if not v.startswith("data:image/jpeg;base64,"):
                                        v = f"data:image/jpeg;base64,{v.lstrip()}"
                        else:
                            v = ""
                    new_det[k] = v

            new_r["detection"] = new_det
            sanitized.append(new_r)

        aggregated["images"] = sanitized

    return aggregated


# Initialize Scratch Detection Pipeline (configurable backends)
dlogger.log("ğŸš€ Scratch Detection Pipeline ì´ˆê¸°í™” ì¤‘...", level="info")
try:
    _SCRATCH_PIPELINE = Pipeline(
        det_backend=os.environ.get("DETECTION_BACKEND", "yolo"),
        anomaly_backend=os.environ.get("ANOMALY_BACKEND", "patchcore"),
        device=os.environ.get("DEVICE", "cuda"),
        det_conf=float(os.environ.get("DETECTION_CONF", 0.25)),
        det_imgsz=int(os.environ.get("DETECTION_IMGSZ", 640)),
        yolo_model=os.environ.get(
            "YOLO_MODEL_PATH", os.path.join("models", "yolo_weights", "best.pt")
        ),
        sam_model=os.environ.get("SAM_MODEL_PATH", "models/sam/FastSAM-s.pt"),
        sam_prompt=os.environ.get("SAM_PROMPT", "car"),
        anomaly_threshold=float(os.environ.get("ANOMALY_THRESHOLD", 33.08)),
        patchcore_ckpt=os.environ.get(
            "PATCHCORE_CHECKPOINT", os.path.join("models", "patch_core")
        ),
    )
    dlogger.log("âœ… Scratch Detection Pipeline ì¤€ë¹„ ì™„ë£Œ!", level="info")
except Exception as e:
    dlogger.log(f"âŒ Scratch Detection Pipeline ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", level="error")
    _SCRATCH_PIPELINE = None

# Load configuration object
env = os.environ.get("FLASK_ENV", "development")


@app.route("/")
def index():
    return jsonify(
        {
            "message": "Welcome to 404-AI Factory Defect Recognition System",
            "status": "running",
        }
    )


@app.route("/health")
def health():
    deps = {}
    try:
        import flask  # noqa: F401

        deps["flask"] = "installed"
    except ImportError:
        deps["flask"] = "not installed"
    try:
        import cv2  # noqa: F401

        deps["opencv"] = "installed"
    except ImportError:
        deps["opencv"] = "not installed"
    try:
        import ultralytics  # noqa: F401

        deps["ultralytics"] = "installed"
    except ImportError:
        deps["ultralytics"] = "not installed"

    all_ok = all(v == "installed" for v in deps.values())
    return jsonify(
        {"status": "healthy" if all_ok else "degraded", "dependencies": deps}
    )


def process_image(
    data: bytes, filename: str = "image.jpg", mimetype: str | None = None
):
    """
    ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ëª¨ë“  ì„œë¹„ìŠ¤ í˜¸ì¶œ
    """
    # ê°€ëŠ¥í•œ ê²½ìš° í¬ë§·/í¬ê¸° ì •ë³´ë¥¼ ì–»ë˜, ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    img_info = validate_image_format(data)
    if not img_info.get("valid"):
        img_info = {
            "valid": True,
            "format": "jpg",
            "extension": ".jpg",
            "mime_type": "image/jpeg",
            "size": len(data),
            "width": 0,
            "height": 0,
        }

    # ìœ íš¨í•œ(ë˜ëŠ” ê¸°ë³¸ê°’) ì´ë¯¸ì§€ ì •ë³´ ë¡œê¹…
    dlogger.log(
        f"ğŸ“¸ ì´ë¯¸ì§€ ìˆ˜ì‹ : {filename} ({img_info['width']}x{img_info['height']}, format={img_info.get('format')}, size={img_info['size']} bytes)",
        level="info",
    )

    # ì‹¤ì œ ê°ì§€(inference) ìˆ˜í–‰
    if "_SCRATCH_PIPELINE" in globals() and _SCRATCH_PIPELINE is not None:
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ run_image ì‚¬ìš©
            with tempfile.NamedTemporaryFile(
                suffix=img_info["extension"], delete=False
            ) as tmp:
                tmp.write(data)
                tmp_path = tmp.name
            # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ (ë””ë²„ê·¸ìš©) â€” use per-process upload session dir
            debug_dir = _UPLOAD_DIR
            # íŒŒì¼ëª…ì€ ì„¸ì…˜ ë‚´ì—ì„œ 1,2,3... í˜•ì‹ìœ¼ë¡œ ì¶©ëŒ íšŒí”¼
            with _UPLOAD_COUNTER_LOCK:
                idx = next(_UPLOAD_COUNTER)
            base_name = os.path.splitext(filename)[0]
            debug_img_path = os.path.join(debug_dir, f"{idx:04d}_{base_name}{img_info['extension']}")
            # ê°ì§€ ìˆ˜í–‰
            from pathlib import Path

            results = _SCRATCH_PIPELINE.run_image(Path(tmp_path), Path(debug_img_path))
            # results: List[Dict], ì‹œê°í™” ì´ë¯¸ì§€ëŠ” debug_img_pathì— ì €ì¥ë¨
            # ê²°ê³¼ ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
            bytes_img = b""
            try:
                with open(debug_img_path, "rb") as f:
                    bytes_img = f.read()
            except Exception:
                bytes_img = b""
            img_base64 = (
                base64.b64encode(bytes_img).decode("utf-8") if bytes_img else ""
            )
            # ê²°ê³¼ ì§‘ê³„
            car_regions = results if isinstance(results, list) else []
            # pipelineì— ìœ„ì„ëœ ì„ ë³„ ë¡œì§ ì‚¬ìš©: toy_car_class ì„ íƒ (ì´ë¯¸ì§€ ê²½ë¡œ ì œê³µ)
            toy_car_class, present_cls = _SCRATCH_PIPELINE.select_toy_car_class(car_regions, image_path=Path(tmp_path))
            toy_car_exists = toy_car_class is not None
            dlogger.log(f"[DEBUG] present_cls={present_cls} -> toy_car_class={toy_car_class}", level="debug")
            if not toy_car_exists:
                scratch_result = {
                    "success": False,
                    "result_image": (f"data:image/jpeg;base64,{img_base64}" if _FORCE_DATA_URI_PREFIX else img_base64),
                    "car_regions": car_regions,
                    "result": "pass",
                    "reason": f"no car (cls in {sorted(list(present_cls))} -> none of 1,4,3,6)",
                }
                dlogger.log("[DEBUG] pipeline summary: no car (cls=1,3,4,6) detected, pass", level="debug")
            else:
                # ì„ íƒëœ toy_car_classì— ëŒ€í•´ì„œë§Œ anomaly ì‹¤í–‰
                augmented = _SCRATCH_PIPELINE.predict_anomalies_for(Path(tmp_path), car_regions, targets={toy_car_class})
                # ì§‘ê³„: scratch(5), broken(placeholder), separated(6)
                scratch_count = sum(1 for r in augmented if r.get("class_id") == 5)
                broken_count = 0
                separated_count = sum(1 for r in augmented if r.get("class_id") == 6)
                # anomaly_detectedëŠ” ì„ íƒëœ toy_car_class ì˜ì—­ì—ì„œì˜ ì´ìƒ ìœ ë¬´
                anomaly_detected = any(
                    (r.get("class_id") == toy_car_class and r.get("anomaly") and r["anomaly"].get("is_anomaly"))
                    for r in augmented
                )
                scratch_result = {
                    "success": True,
                    "result_image": (f"data:image/jpeg;base64,{img_base64}" if _FORCE_DATA_URI_PREFIX else img_base64),
                    "scratch_detected": bool(scratch_count),
                    "broken_detected": bool(broken_count),
                    "separated_detected": bool(separated_count),
                    "anomaly_detected": bool(anomaly_detected),
                    "scratch_count": scratch_count,
                    "broken_count": broken_count,
                    "separated_count": separated_count,
                    "car_regions": augmented,
                    "result": ("defect" if anomaly_detected else "ok"),
                }
                dlogger.log(f"[DEBUG] pipeline summary: toy_car_class={toy_car_class} anomaly_detected={anomaly_detected}", level="debug")
            try:
                os.unlink(tmp_path)
            except Exception:
                pass
        except Exception as e:
            scratch_result = {"error": "detection_exception", "detail": str(e)}
    else:
        scratch_result = {"skipped": True, "reason": "scratch_pipeline_not_configured"}

    # Derive top-level result: prefer the pipeline's per-image `result` when present.
    # Map internal 'pass' -> top-level 'ok'. Fallback to 'defect' if any defect flags present.
    overall_result = "ok"
    try:
        if isinstance(scratch_result, dict):
            det_res = scratch_result.get("result")
            if det_res:
                # Preserve pipeline's explicit result values ('pass', 'ok', 'defect')
                overall_result = det_res
            else:
                if (
                    scratch_result.get("scratch_detected")
                    or scratch_result.get("broken_detected")
                    or scratch_result.get("separated_detected")
                    or scratch_result.get("anomaly_detected")
                ):
                    overall_result = "defect"
    except Exception:
        overall_result = "ok"

    return {
        "id": str(uuid.uuid4()),
        "result": overall_result,
        "detection": scratch_result,
        "timestamp": datetime.now().isoformat(),
    }


@app.route("/detect", methods=["POST"])
def detect():
    # JSON ë°©ì‹ ì§€ì›: images: [{image: ...}, ...]
    images = []
    if request.is_json:
        req_json = request.get_json()
        dlogger.log(f"[DEBUG] /detect JSON payload: {json.dumps(req_json, ensure_ascii=False)}", level="debug")
        images = req_json.get("images", [])
        # imagesê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not images:
            return jsonify({"error": "no images in JSON payload"}), 400
        def get_image_bytes(imgobj):
            b64 = imgobj.get("image", "")
            if b64.startswith("data:") and "base64," in b64:
                b64 = b64.split("base64,", 1)[1]
            try:
                return base64.b64decode(b64)
            except Exception:
                return b""
        image_datas = [(get_image_bytes(img), f"json_image_{i}.png") for i, img in enumerate(images)]
    elif "image" in request.files:
        files = request.files.getlist("image")
        image_datas = [(file.read(), file.filename or datetime.now().isoformat()) for file in files if file.filename != ""]
        if not image_datas:
            return jsonify({"error": "no image file provided"}), 400
    else:
        return jsonify({"error": "no image data provided"}), 400

    result_images = []
    total_scratch_count = 0
    total_broken_count = 0
    total_separated_count = 0
    total_car_regions = []
    detected_any = False
    reasons = []

    # Collect per-image responses for batching behavior
    responses = []
    non_pass_responses = []
    for data, fname in image_datas:
        if not data:
            continue
        resp = process_image(data, filename=fname, mimetype=None)
        responses.append(resp)

        det = resp.get("detection", {})
        car_regions = det.get("car_regions", [])
        # car_regionsê°€ ì—†ìœ¼ë©´ ì´ ì´ë¯¸ì§€ëŠ” ì™„ì „íˆ ë¬´ì‹œ
        if not car_regions:
            continue
        # result_imageë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ìŒ (í•­ìƒ prefix ë³´ì¥)
        img = det.get("result_image")
        if img:
            if not img.startswith("data:image/jpeg;base64,"):
                img = f"data:image/jpeg;base64,{img.lstrip()}"
            result_images.append(img)
        else:
            result_images.append("")
        # count í•©ì‚°
        total_scratch_count += det.get("scratch_count", 0)
        total_broken_count += det.get("broken_count", 0)
        total_separated_count += det.get("separated_count", 0)
        total_car_regions.extend(car_regions)
        if det.get("result") != "pass":
            detected_any = True
            non_pass_responses.append(resp)
        if "reason" in det:
            reasons.append(det["reason"])

    # MQTT publish: if input was a list, publish batched list (aligned to input order)
    # only when NOT all images are 'pass'. For single-image input, publish single
    # response object unless it is 'pass'.
    if len(non_pass_responses) == 0:
        dlogger.log("HTTP /detect: publish skipped â€” all images result == 'pass'", level="info")
    else:
            try:
                # build a publish payload that includes per-image details
                publish_payload = aggregate_batch_response(responses, include_images=True)

                if _MQTT_CLIENT is not None:
                    publish_with_client(_MQTT_CLIENT, publish_payload, topic=_OUT_TOPIC, qos=_OUT_QOS)
                else:
                    publish_mqtt(publish_payload)
            except Exception:
                try:
                    publish_mqtt(publish_payload)
                except Exception:
                    dlogger.log("Failed to publish HTTP-detect batched result", level="error")
    # ìµœì¢… ì‘ë‹µ dict êµ¬ì„±: MQTTì— ë°œí–‰í•œ ê²ƒê³¼ ë™ì¼í•œ êµ¬ì¡°ë¡œ ë°˜í™˜
    # (per-image ìƒì„¸ í¬í•¨ ì—¬ë¶€ëŠ” include_images=Trueë¡œ í†µì¼)
    aggregated = aggregate_batch_response(responses, include_images=True)
    return jsonify(aggregated)


# Start MQTT listener now that `process_image` and helpers are defined.
try:
    _MQTT_CLIENT = start_paho_listener(
        process_image_cb=process_image,
        validate_image_format_cb=validate_image_format,
        aggregate_fn=aggregate_batch_response,
        upload_dir=_UPLOAD_DIR,
        upload_counter=_UPLOAD_COUNTER,
        upload_counter_lock=_UPLOAD_COUNTER_LOCK,
        logger=dlogger,
        executor=_EXECUTOR,
        broker=_MQTT_BROKER,
        port=_MQTT_PORT,
        use_tls=_MQTT_TLS,
        in_topic=_IN_TOPIC,
        out_topic=_OUT_TOPIC,
        out_qos=_OUT_QOS,
        send_ack=_MQTT_SEND_ACK,
        ack_topic=_MQTT_ACK_TOPIC,
    )
except Exception as e:
    _MQTT_CLIENT = None
    dlogger.log(f"MQTT client init failed: {e}", level="error")


if __name__ == "__main__":
    debug = os.environ.get("DEBUG", "False").lower() in ("true", "1", "t")
    host = os.environ.get("HOST", "0.0.0.0")
    port = int(os.environ.get("PORT", 5000))
    app.run(debug=debug, use_reloader=False, host=host, port=port)
