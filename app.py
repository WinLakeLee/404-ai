"""
404-AI orchestrator (Flask): proxies image uploads to vision  services.
Inference service: app.py (YOLO + PatchCore)
"""

import os
import json
import requests
import sys
from concurrent.futures import ThreadPoolExecutor
import uuid
from flask import Flask, jsonify, request
from mqtt_utils import (
    create_paho_client,
    publish_with_client,
    publish_mqtt,
    is_client_connected,
)
import threading
from datetime import datetime
import time
from dotenv import load_dotenv
from pipeline import Pipeline
import tempfile
import numpy as np
from PIL import Image
import io
import re
import base64
from _daily_logger import DailyLogger
from itertools import count

# Load environment variables from .env (or DOTENV_PATH) before reading any settings
load_dotenv(dotenv_path=os.environ.get("DOTENV_PATH", ".env"), override=True)

app = Flask(__name__)
_EXECUTOR = ThreadPoolExecutor(max_workers=int(os.environ.get("APP_WORKERS", 4)))
dlogger = DailyLogger()

# Create a per-process upload session directory at app start to avoid
# filename collisions when multiple images arrive with the same timestamps.
# Files will be saved under debug/session_<YYYYMMDD>T<HHMMSS>/ and named 1.ext, 2.ext, ...
_UPLOAD_SESSION = datetime.now().strftime("session_%Y%m%dT%H%M%S")
_UPLOAD_DIR = os.path.join(os.getcwd(), "debug", _UPLOAD_SESSION)
os.makedirs(_UPLOAD_DIR, exist_ok=True)
# thread-safe counter for filenames
_UPLOAD_COUNTER = count(1)
_UPLOAD_COUNTER_LOCK = threading.Lock()

# MQTT settings (single broker for pub/sub)
_MQTT_BROKER = os.environ.get("MQTT_BROKER") or "localhost"

_MQTT_PORT = int(os.environ.get("MQTT_PORT") or 1883)
_MQTT_TLS = (os.environ.get("MQTT_TLS") or "0").lower() in ("1", "true", "yes")
_MQTT_KEEPALIVE = int(os.environ.get("MQTT_KEEPALIVE", 60))
_IN_TOPIC = os.environ.get("IN_MQTT_TOPIC") or "camera01/control"
_OUT_TOPIC = os.environ.get("MQTT_TOPIC") or "camera01/result"
_OUT_QOS = int(os.environ.get("OUT_MQTT_QOS") or os.environ.get("MQTT_QOS") or 1)

# ACK behavior: don't publish ACKs to the main result topic by default.
# Set `MQTT_SEND_ACK=1` to enable ACKs, and `MQTT_ACK_TOPIC` to change the ack topic.
_MQTT_SEND_ACK = (os.environ.get("MQTT_SEND_ACK") or "0").lower() in ("1", "true", "yes")
_MQTT_ACK_TOPIC = os.environ.get("MQTT_ACK_TOPIC") or None

app.config["MQTT_BROKER_URL"] = _MQTT_BROKER
app.config["MQTT_BROKER_PORT"] = _MQTT_PORT
app.config["MQTT_KEEPALIVE"] = _MQTT_KEEPALIVE
app.config["MQTT_TLS_ENABLED"] = _MQTT_TLS
app.config["MQTT_CLEAN_SESSION"] = True

# Create a persistent paho client and wire callbacks. If broker is down,
# create_paho_client will return a client (and log connection failure) but
# publishing will be best-effort.
_MQTT_CLIENT = None
try:

    def _normalize_payload(data: bytes):
        from mqtt_utils import find_base64_image
        return find_base64_image(data)

    def _on_message(client, userdata, message):
        def _task():
            # Normalize/decode MQTT payload (handle hex, JSON with base64, raw base64)

            payload_result = _normalize_payload(message.payload)
            dlogger.log(f"[MQTT DEBUG] find_base64_image result type: {type(payload_result)}", level="debug")
            if isinstance(payload_result, dict) and "image" in payload_result:
                img_val = payload_result["image"]
                if isinstance(img_val, list):
                    dlogger.log(f"[MQTT DEBUG] image count: {len(img_val)}; sizes: {[len(b) for b in img_val]}", level="debug")
                elif isinstance(img_val, bytes):
                    dlogger.log(f"[MQTT DEBUG] single image size: {len(img_val)}", level="debug")
                else:
                    dlogger.log(f"[MQTT DEBUG] image value type: {type(img_val)}", level="debug")
            else:
                dlogger.log(f"[MQTT DEBUG] payload_result: {payload_result}", level="debug")
            # ì‹¤ì œ ì´ë¯¸ì§€ ë°”ì´íŠ¸ë“¤ë§Œ ì¶”ì¶œ (ë‹¨ì¼ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)
            images = []
            if isinstance(payload_result, dict) and "image" in payload_result:
                img_val = payload_result["image"]
                if isinstance(img_val, list):
                    images = img_val
                else:
                    images = [img_val]
            else:
                images = [payload_result]

            # Optional ACK/heartbeat to indicate message received. Send once per incoming message.
            try:
                if _MQTT_SEND_ACK:
                    ack_topic = _MQTT_ACK_TOPIC or f"{_OUT_TOPIC}_ack"
                    publish_with_client(
                        _MQTT_CLIENT,
                        {"id": _MQTT_BROKER, "timestamp": datetime.now().isoformat()},
                        topic=ack_topic,
                        qos=_OUT_QOS,
                    )
            except Exception:
                if _MQTT_SEND_ACK:
                    try:
                        publish_mqtt(payload={"error": ConnectionRefusedError()})
                    except Exception:
                        pass

            # ê° ì´ë¯¸ì§€ë¥¼ ìˆœíšŒí•˜ì—¬ ì²˜ë¦¬
            responses = []
            non_pass_responses = []
            for idx, payload in enumerate(images, start=1):
                # ì¶”ê°€ ë””ë²„ê·¸: ì¶”ì¶œëœ payload ì •ë³´(íƒ€ì…/í¬ê¸°/í—¤ë“œ)ë¥¼ ë¡œê·¸ì— ë‚¨ê¹€
                try:
                    if isinstance(payload, (bytes, bytearray)):
                        plen = len(payload)
                        dlogger.log(f"[MQTT DEBUG] extracted payload type={type(payload)}, len={plen}", level="debug")
                        if plen:
                            dlogger.log(f"[MQTT DEBUG] payload head hex: {payload[:32].hex()}", level="debug")
                    else:
                        s = str(payload)
                        dlogger.log(f"[MQTT DEBUG] extracted payload type={type(payload)}, repr head={s[:128]!r}", level="debug")
                except Exception as _e:
                    dlogger.log(f"[MQTT DEBUG] payload debug failed: {_e}", level="debug")

                # í¬ë§· ê²€ì¦
                img_info = validate_image_format(payload)
                if not img_info.get("valid"):
                    img_info = {
                        "valid": True,
                        "format": "jpg",
                        "extension": ".jpg",
                        "mime_type": "image/jpeg",
                        "size": len(payload),
                        "width": 0,
                        "height": 0,
                    }

                # ìœ íš¨í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ (íŒŒì¼ëª…ì— ì¸ë±ìŠ¤ ì¶”ê°€)
                base_name = f"mqtt_{message.topic.replace('/', '_')}"
                if len(images) > 1:
                    filename = f"{base_name}_{idx}{img_info['extension']}"
                else:
                    filename = f"{base_name}{img_info['extension']}"
                dlogger.log(
                    f"âœ… MQTT ì´ë¯¸ì§€ ìˆ˜ì‹ : {filename} ({img_info['width']}x{img_info['height']}, {img_info['size']} bytes)",
                    level="info",
                )

                # use normalized payload (may have been decoded from hex/base64/JSON)
                resp = process_image(payload, filename, img_info["mime_type"])
                responses.append(resp)
                if resp.get("detection", {}).get("result") != "pass":
                    non_pass_responses.append(resp)
                else:
                    dlogger.log(f"Image {idx} detection result == 'pass' (no car); will skip publishing for this image unless another image requires publish)", level="debug")

            # After processing all images in this MQTT message, publish only if
            # at least one image has result != 'pass'. If so, publish all non-pass responses.
            if len(non_pass_responses) == 0:
                dlogger.log("MQTT publish skipped: all images result == 'pass' (no car)", level="info")
            else:
                # If the incoming payload contained multiple images, publish a
                # single batched message with a result list aligned to the input
                # order (`responses`). If the input was a single image, publish
                # the single response dict as before.
                # Use shared aggregation helper to build the top-level response
                aggregated = aggregate_batch_response(responses)
                try:
                    publish_with_client(_MQTT_CLIENT, aggregated, topic=_OUT_TOPIC, qos=_OUT_QOS)
                except Exception:
                    publish_mqtt(aggregated)

        _EXECUTOR.submit(_task)

    _MQTT_CLIENT = create_paho_client(
        on_message_cb=_on_message,
        broker=_MQTT_BROKER,
        port=_MQTT_PORT,
        use_tls=_MQTT_TLS,
        subscribe_topic=_IN_TOPIC,
        qos=_OUT_QOS,
        start_loop=True,
    )
except Exception as e:
    _MQTT_CLIENT = None
    dlogger.log(f"MQTT client init failed: {e}", level="error")


# Start a background monitor that periodically prints MQTT connection info.
def _start_mqtt_monitor(interval: int = 10):
    def _monitor():
        while True:
            try:
                connected = is_client_connected(_MQTT_CLIENT)
                now = datetime.now().isoformat()
                dlogger.log(
                    f"[{now}] MQTT status: connected={connected} broker={_MQTT_BROKER}:{_MQTT_PORT} in_topic={_IN_TOPIC} out_topic={_OUT_TOPIC}",
                    level="info",
                )
            except Exception:
                dlogger.log(f"[{datetime.now().isoformat()}] MQTT status: check failed", level="warning")
            time.sleep(interval)

    t = threading.Thread(target=_monitor, daemon=True)
    t.start()


_start_mqtt_monitor()


# Image format validation functions
def validate_image_format(data: bytes) -> dict:
    """
    ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°ì˜ í˜•ì‹ì„ ê²€ì¦í•˜ê³  íŒŒì¼ í™•ì¥ì, MIME íƒ€ì… ë°˜í™˜

    Returns:
        {
            'valid': bool,
            'format': str (jpg, png, bmp, etc),
            'extension': str (.jpg, .png, etc),
            'mime_type': str,
            'size': int (bytes),
            'width': int,
            'height': int,
            'error': str (if valid=False)
        }
    """
    if not data or len(data) == 0:
        return {"valid": False, "error": "ì´ë¯¸ì§€ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    # íŒŒì¼ ì‹œê·¸ë‹ˆì²˜(ë§¤ì§ ë„˜ë²„)ë¡œ í˜•ì‹ ê²€ì¦
    magic_numbers = {
        b"\xff\xd8\xff": ("jpg", ".jpg", "image/jpeg"),  # JPEG
        b"\x89PNG": ("png", ".png", "image/png"),  # PNG
        b"BM": ("bmp", ".bmp", "image/bmp"),  # BMP
        b"GIF87a": ("gif", ".gif", "image/gif"),  # GIF87a
        b"GIF89a": ("gif", ".gif", "image/gif"),  # GIF89a
    }

    detected_format = None
    for magic, (fmt, ext, mime) in magic_numbers.items():
        if data.startswith(magic):
            detected_format = (fmt, ext, mime)
            break

    if not detected_format:
        return {
            "valid": False,
            "size": len(data),
            "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤ (ì²˜ìŒ 4ë°”ì´íŠ¸: {data[:4].hex()})",
        }

    fmt, ext, mime = detected_format

    # ì´ë¯¸ì§€ ì•ˆì „ì„± ê²€ì‚¬: PIL ê²€ì¦, ì¹˜ìˆ˜/í”½ì…€ìˆ˜ ì œí•œ, ì˜ì‹¬ ì„œëª… ìŠ¤ìº”
    try:
        # í™˜ê²½ ë³€ìˆ˜ë¡œ ì œí•œê°’ì„ ì¡°ì • ê°€ëŠ¥
        try:
            max_pixels = int(os.environ.get("IMAGE_MAX_PIXELS", "30000000"))
        except Exception:
            max_pixels = 30000000
        Image.MAX_IMAGE_PIXELS = max_pixels

        # ë¨¼ì € ë¹ ë¥´ê²Œ ê²€ì¦(verify)í•˜ì—¬ ì†ìƒ ì—¬ë¶€ í™•ì¸
        img = Image.open(io.BytesIO(data))
        img.verify()

        # ì‹¤ì œ í¬ê¸°ë¥¼ ì–»ê¸° ìœ„í•´ ë‹¤ì‹œ ì—´ê¸°
        img = Image.open(io.BytesIO(data))
        width, height = img.size

        try:
            max_w = int(os.environ.get("IMAGE_MAX_WIDTH", "10000"))
            max_h = int(os.environ.get("IMAGE_MAX_HEIGHT", "10000"))
            min_w = int(os.environ.get("IMAGE_MIN_WIDTH", "1"))
            min_h = int(os.environ.get("IMAGE_MIN_HEIGHT", "1"))
        except Exception:
            max_w, max_h, min_w, min_h = 10000, 10000, 1, 1

        if width <= 0 or height <= 0:
            return {"valid": False, "size": len(data), "error": "ì´ë¯¸ì§€ ì¹˜ìˆ˜ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}

        if width < min_w or height < min_h:
            return {"valid": False, "size": len(data), "error": f"ì´ë¯¸ì§€ ì¹˜ìˆ˜ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ ({width}x{height})"}

        if width > max_w or height > max_h:
            return {"valid": False, "size": len(data), "error": f"ì´ë¯¸ì§€ ì¹˜ìˆ˜ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤ ({width}x{height})"}

        # ê°„ë‹¨í•œ ì„œëª… ìŠ¤ìº”: í—¤ë”/ì•ë¶€ë¶„ì—ì„œ ìŠ¤í¬ë¦½íŠ¸/ì‹¤í–‰ íŒŒì¼/ì••ì¶• ì•„ì¹´ì´ë¸Œ í”ì  ê²€ì¶œ
        head = data[:4096].lower()
        suspicious_signatures = [b"<?php", b"<script", b"javascript:", b"pk\x03\x04", b"mz", b"#!/bin/sh", b"<!doctype html"]
        for sig in suspicious_signatures:
            if sig in head:
                return {"valid": False, "size": len(data), "error": f"ì˜ì‹¬ ì„œëª… ë°œê²¬: {sig.decode('latin1', 'ignore')}"}

        return {
            "valid": True,
            "format": fmt,
            "extension": ext,
            "mime_type": mime,
            "size": len(data),
            "width": width,
            "height": height,
        }
    except Image.DecompressionBombError as e:
        return {"valid": False, "size": len(data), "error": f"ì´ë¯¸ì§€ ë””ì»´í”„ë ˆìŠ¤ í­íƒ„ ì˜ì‹¬: {str(e)}"}
    except Exception as e:
        return {"valid": False, "size": len(data), "format": fmt, "error": f"ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {str(e)}"}


def aggregate_batch_response(responses: list) -> dict:
    """
    Given a list of per-image response dicts (as returned by `process_image`),
    compute the aggregated top-level response structure used by HTTP `/detect`
    and MQTT publications.

    Returns a dict with keys: result, scratch_count, broken_count,
    separated_count, result_image (list), car_regions (list), reason, timestamp
    """
    total_scratch_count = 0
    total_broken_count = 0
    total_separated_count = 0
    total_car_regions = []
    result_images = []
    detected_any = False
    reasons = []

    for resp in responses:
        det = resp.get("detection", {})
        total_scratch_count += det.get("scratch_count", 0)
        total_broken_count += det.get("broken_count", 0)
        total_separated_count += det.get("separated_count", 0)
        total_car_regions.extend(det.get("car_regions", []))
        rimg = det.get("result_image")
        if rimg:
            if not isinstance(rimg, str):
                rimg = str(rimg)
            if not rimg.startswith("data:image/jpeg;base64,"):
                rimg = f"data:image/jpeg;base64,{rimg.lstrip()}"
            result_images.append(rimg)
        else:
            result_images.append("")
        if det.get("result") != "pass":
            detected_any = True
        if "reason" in det:
            reasons.append(det.get("reason"))

    aggregated = {
        "result": "defect" if detected_any else "ok",
        "scratch_count": total_scratch_count,
        "broken_count": total_broken_count,
        "separated_count": total_separated_count,
        "result_image": result_images,
        "car_regions": total_car_regions,
        "reason": "; ".join(reasons) if reasons else None,
        "timestamp": datetime.now().isoformat(),
    }
    return aggregated


# Initialize Scratch Detection Pipeline (configurable backends)
dlogger.log("ğŸš€ Scratch Detection Pipeline ì´ˆê¸°í™” ì¤‘...", level="info")
try:
    _SCRATCH_PIPELINE = Pipeline(
        det_backend=os.environ.get("DETECTION_BACKEND", "yolo"),
        anomaly_backend=os.environ.get("ANOMALY_BACKEND", "patchcore"),
        device=os.environ.get("DEVICE", "cuda"),
        det_conf=float(os.environ.get("DETECTION_CONF", 0.25)),
        det_imgsz=int(os.environ.get("DETECTION_IMGSZ", 640)),
        yolo_model=os.environ.get(
            "YOLO_MODEL_PATH", os.path.join("models", "yolo_weights", "best.pt")
        ),
        sam_model=os.environ.get("SAM_MODEL_PATH", "FastSAM-s.pt"),
        sam_prompt=os.environ.get("SAM_PROMPT", "car"),
        anomaly_threshold=float(os.environ.get("ANOMALY_THRESHOLD", 33.08)),
        patchcore_ckpt=os.environ.get(
            "PATCHCORE_CHECKPOINT", os.path.join("models", "patch_core")
        ),
    )
    dlogger.log("âœ… Scratch Detection Pipeline ì¤€ë¹„ ì™„ë£Œ!", level="info")
except Exception as e:
    dlogger.log(f"âŒ Scratch Detection Pipeline ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", level="error")
    _SCRATCH_PIPELINE = None

# Load configuration object
env = os.environ.get("FLASK_ENV", "development")


@app.route("/")
def index():
    return jsonify(
        {
            "message": "Welcome to 404-AI Factory Defect Recognition System",
            "status": "running",
        }
    )


@app.route("/health")
def health():
    deps = {}
    try:
        import flask  # noqa: F401

        deps["flask"] = "installed"
    except ImportError:
        deps["flask"] = "not installed"
    try:
        import cv2  # noqa: F401

        deps["opencv"] = "installed"
    except ImportError:
        deps["opencv"] = "not installed"
    try:
        import ultralytics  # noqa: F401

        deps["ultralytics"] = "installed"
    except ImportError:
        deps["ultralytics"] = "not installed"

    all_ok = all(v == "installed" for v in deps.values())
    return jsonify(
        {"status": "healthy" if all_ok else "degraded", "dependencies": deps}
    )


def process_image(
    data: bytes, filename: str = "image.jpg", mimetype: str | None = None
):
    """
    ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ëª¨ë“  ì„œë¹„ìŠ¤ í˜¸ì¶œ
    """
    # ê°€ëŠ¥í•œ ê²½ìš° í¬ë§·/í¬ê¸° ì •ë³´ë¥¼ ì–»ë˜, ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    img_info = validate_image_format(data)
    if not img_info.get("valid"):
        img_info = {
            "valid": True,
            "format": "jpg",
            "extension": ".jpg",
            "mime_type": "image/jpeg",
            "size": len(data),
            "width": 0,
            "height": 0,
        }

    # ìœ íš¨í•œ(ë˜ëŠ” ê¸°ë³¸ê°’) ì´ë¯¸ì§€ ì •ë³´ ë¡œê¹…
    dlogger.log(
        f"ğŸ“¸ ì´ë¯¸ì§€ ìˆ˜ì‹ : {filename} ({img_info['width']}x{img_info['height']}, format={img_info.get('format')}, size={img_info['size']} bytes)",
        level="info",
    )

    # ì‹¤ì œ ê°ì§€(inference) ìˆ˜í–‰
    if "_SCRATCH_PIPELINE" in globals() and _SCRATCH_PIPELINE is not None:
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ run_image ì‚¬ìš©
            with tempfile.NamedTemporaryFile(
                suffix=img_info["extension"], delete=False
            ) as tmp:
                tmp.write(data)
                tmp_path = tmp.name
            # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ (ë””ë²„ê·¸ìš©) â€” use per-process upload session dir
            debug_dir = _UPLOAD_DIR
            # íŒŒì¼ëª…ì€ ì„¸ì…˜ ë‚´ì—ì„œ 1,2,3... í˜•ì‹ìœ¼ë¡œ ì¶©ëŒ íšŒí”¼
            with _UPLOAD_COUNTER_LOCK:
                idx = next(_UPLOAD_COUNTER)
            base_name = os.path.splitext(filename)[0]
            debug_img_path = os.path.join(debug_dir, f"{idx:04d}_{base_name}{img_info['extension']}")
            # ê°ì§€ ìˆ˜í–‰
            from pathlib import Path

            results = _SCRATCH_PIPELINE.run_image(Path(tmp_path), Path(debug_img_path))
            # results: List[Dict], ì‹œê°í™” ì´ë¯¸ì§€ëŠ” debug_img_pathì— ì €ì¥ë¨
            # ê²°ê³¼ ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
            bytes_img = b""
            try:
                with open(debug_img_path, "rb") as f:
                    bytes_img = f.read()
            except Exception:
                bytes_img = b""
            img_base64 = (
                base64.b64encode(bytes_img).decode("utf-8") if bytes_img else ""
            )
            # ê²°ê³¼ ì§‘ê³„
            car_regions = results if isinstance(results, list) else []
            # ìë™ì°¨(cls=1,2)ê°€ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ pass ì²˜ë¦¬
            car_detected = any(r.get("class_id") in (1, 2) for r in car_regions)
            if not car_detected:
                scratch_result = {
                    "success": False,
                    "result_image": f"data:image/jpeg;base64,{img_base64}",
                    "car_regions": car_regions,
                    "result": "pass",
                    "reason": "no car (cls=1,2) detected",
                }
                dlogger.log("[DEBUG] pipeline summary: no car (cls=1,2) detected, pass", level="debug")
            else:
                scratch_count = sum(1 for r in car_regions if r.get("class_id") == 5)
                broken_count = 0  # í•„ìš”ì‹œ í´ë˜ìŠ¤ë³„ë¡œ ì§‘ê³„
                separated_count = sum(1 for r in car_regions if r.get("class_id") == 6)
                scratch_result = {
                    "success": True,
                    "result_image": f"data:image/jpeg;base64,{img_base64}",
                    "scratch_detected": bool(scratch_count),
                    "broken_detected": bool(broken_count),
                    "separated_detected": bool(separated_count),
                    "anomaly_detected": bool(scratch_count),
                    "scratch_count": scratch_count,
                    "broken_count": broken_count,
                    "separated_count": separated_count,
                    "car_regions": car_regions,
                    "result": ("defect" if scratch_count > 0 else "ok"),
                }
                dlogger.log(f"[DEBUG] pipeline summary: scratch_count={scratch_count}", level="debug")
            try:
                os.unlink(tmp_path)
            except Exception:
                pass
        except Exception as e:
            scratch_result = {"error": "detection_exception", "detail": str(e)}
    else:
        scratch_result = {"skipped": True, "reason": "scratch_pipeline_not_configured"}

    # Derive top-level result: prefer the pipeline's per-image `result` when present.
    # Map internal 'pass' -> top-level 'ok'. Fallback to 'defect' if any defect flags present.
    overall_result = "ok"
    try:
        if isinstance(scratch_result, dict):
            det_res = scratch_result.get("result")
            if det_res:
                # Preserve pipeline's explicit result values ('pass', 'ok', 'defect')
                overall_result = det_res
            else:
                if (
                    scratch_result.get("scratch_detected")
                    or scratch_result.get("broken_detected")
                    or scratch_result.get("separated_detected")
                    or scratch_result.get("anomaly_detected")
                ):
                    overall_result = "defect"
    except Exception:
        overall_result = "ok"

    return {
        "id": str(uuid.uuid4()),
        "result": overall_result,
        "detection": scratch_result,
        "timestamp": datetime.now().isoformat(),
    }


@app.route("/detect", methods=["POST"])
def detect():
    # JSON ë°©ì‹ ì§€ì›: images: [{image: ...}, ...]
    images = []
    if request.is_json:
        req_json = request.get_json()
        dlogger.log(f"[DEBUG] /detect JSON payload: {json.dumps(req_json, ensure_ascii=False)}", level="debug")
        images = req_json.get("images", [])
        # imagesê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not images:
            return jsonify({"error": "no images in JSON payload"}), 400
        def get_image_bytes(imgobj):
            b64 = imgobj.get("image", "")
            if b64.startswith("data:") and "base64," in b64:
                b64 = b64.split("base64,", 1)[1]
            try:
                return base64.b64decode(b64)
            except Exception:
                return b""
        image_datas = [(get_image_bytes(img), f"json_image_{i}.png") for i, img in enumerate(images)]
    elif "image" in request.files:
        files = request.files.getlist("image")
        image_datas = [(file.read(), file.filename or datetime.now().isoformat()) for file in files if file.filename != ""]
        if not image_datas:
            return jsonify({"error": "no image file provided"}), 400
    else:
        return jsonify({"error": "no image data provided"}), 400

    result_images = []
    total_scratch_count = 0
    total_broken_count = 0
    total_separated_count = 0
    total_car_regions = []
    detected_any = False
    reasons = []

    # Collect per-image responses for batching behavior
    responses = []
    non_pass_responses = []
    for data, fname in image_datas:
        if not data:
            continue
        resp = process_image(data, filename=fname, mimetype=None)
        responses.append(resp)

        det = resp.get("detection", {})
        car_regions = det.get("car_regions", [])
        # car_regionsê°€ ì—†ìœ¼ë©´ ì´ ì´ë¯¸ì§€ëŠ” ì™„ì „íˆ ë¬´ì‹œ
        if not car_regions:
            continue
        # result_imageë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ìŒ (í•­ìƒ prefix ë³´ì¥)
        img = det.get("result_image")
        if img:
            if not img.startswith("data:image/jpeg;base64,"):
                img = f"data:image/jpeg;base64,{img.lstrip()}"
            result_images.append(img)
        else:
            result_images.append("")
        # count í•©ì‚°
        total_scratch_count += det.get("scratch_count", 0)
        total_broken_count += det.get("broken_count", 0)
        total_separated_count += det.get("separated_count", 0)
        total_car_regions.extend(car_regions)
        if det.get("result") != "pass":
            detected_any = True
            non_pass_responses.append(resp)
        if "reason" in det:
            reasons.append(det["reason"])

    # MQTT publish: if input was a list, publish batched list (aligned to input order)
    # only when NOT all images are 'pass'. For single-image input, publish single
    # response object unless it is 'pass'.
    if len(non_pass_responses) == 0:
        dlogger.log("HTTP /detect: publish skipped â€” all images result == 'pass'", level="info")
    else:
        try:
            if len(image_datas) > 1:
                batched = {
                    "id": str(uuid.uuid4()),
                    "timestamp": datetime.now().isoformat(),
                    "source": "http:/detect",
                    "images": responses,
                }
            else:
                # single-image input: publish single non-pass response
                batched = non_pass_responses[0]

            if _MQTT_CLIENT is not None:
                publish_with_client(_MQTT_CLIENT, batched, topic=_OUT_TOPIC, qos=_OUT_QOS)
            else:
                publish_mqtt(batched)
        except Exception:
            try:
                publish_mqtt(batched)
            except Exception:
                dlogger.log("Failed to publish HTTP-detect batched result", level="error")
    # ìµœì¢… ì‘ë‹µ dict êµ¬ì„± (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    aggregated = aggregate_batch_response(responses)
    return jsonify(aggregated)


if __name__ == "__main__":
    debug = os.environ.get("DEBUG", "False").lower() in ("true", "1", "t")
    host = os.environ.get("HOST", "0.0.0.0")
    port = int(os.environ.get("PORT", 5000))
    app.run(debug=debug, use_reloader=False, host=host, port=port)
